{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03282d5a-dcc3-4a0c-a80c-4ba910f89751",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-16 13:11:45.205547: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-04-16 13:11:45.266532: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-04-16 13:11:45.267300: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-16 13:11:46.179199: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4582c927-c46e-47a6-a529-1f095a2596e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "church_test = \"/datalake/datasets/ML_Davis/image-matching-challenge-2024/test/church/images\"\n",
    "lizard_test = \"/datalake/datasets/ML_Davis/image-matching-challenge-2024/test/lizard/images\"\n",
    "church_train = \"/datalake/datasets/ML_Davis/image-matching-challenge-2024/train/church/images\"\n",
    "pond_train = \"/datalake/datasets/ML_Davis/image-matching-challenge-2024/train/pond/images\"\n",
    "lizard_train = \"/datalake/datasets/ML_Davis/image-matching-challenge-2024/train/lizard/images\"\n",
    "dioscuri_train = \"/datalake/datasets/ML_Davis/image-matching-challenge-2024/train/dioscuri/images\"\n",
    "cup_train = \"/datalake/datasets/ML_Davis/image-matching-challenge-2024/train/transp_obj_glass_cup/images\"\n",
    "cylinder_train = \"/datalake/datasets/ML_Davis/image-matching-challenge-2024/train/transp_obj_glass_cylinder/images\"\n",
    "temple_train = \"/datalake/datasets/ML_Davis/image-matching-challenge-2024/train/multi-temporal-temple-baalshamin/images\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e045046-08d9-4203-bfe2-254534aa7f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_binary_classification_cnn(input_shape):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(64, activation='relu'))\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f7315ab-0c2a-4dbe-b269-b7bfb8c718ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_and_labels(base_dirs, target_size=(128, 128)):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for base_dir in base_dirs:\n",
    "        #print(f\"Processing directory: {base_dir}\")\n",
    "        if os.path.isdir(base_dir):\n",
    "            for file_name in sorted(os.listdir(base_dir)):\n",
    "                file_path = os.path.join(base_dir, file_name)\n",
    "                if file_name.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                    #print(f\"Loading image: {file_path}\")\n",
    "                    img = image.load_img(file_path, target_size=target_size)\n",
    "                    img_array = image.img_to_array(img)\n",
    "                    images.append(img_array)\n",
    "                    label = 1 if 'church' in base_dir else 0\n",
    "                    labels.append(label)\n",
    "        else:\n",
    "            print(f\"Not a directory: {base_dir}\")\n",
    "    if not images:\n",
    "        print(\"No images found after processing. Check the file paths and extensions.\")\n",
    "    else:\n",
    "        print(f\"Loaded {len(images)} images successfully.\")\n",
    "    return np.array(images), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "600e8434-1bbd-402c-858e-3230c2484886",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 485 images successfully.\n",
      "Loaded 90 images successfully.\n"
     ]
    }
   ],
   "source": [
    "# Directory paths\n",
    "train_dirs = [church_train, lizard_train, pond_train, dioscuri_train, cup_train, cylinder_train, temple_train]\n",
    "test_dirs = [church_test, lizard_test]\n",
    "\n",
    "# Load training and testing images\n",
    "train_images, train_labels = load_images_and_labels(train_dirs)\n",
    "test_images, test_labels = load_images_and_labels(test_dirs)\n",
    "\n",
    "# Calculate steps per epoch and validation steps\n",
    "steps_per_epoch = max(len(train_images) // 20, 1)  # Ensure at least one step\n",
    "validation_steps = max(len(test_images) // 20, 1)  # Ensure at least one step\n",
    "\n",
    "# Data generators\n",
    "train_datagen = ImageDataGenerator(rescale=1./255, rotation_range=40, width_shift_range=0.2, height_shift_range=0.2, shear_range=0.2, zoom_range=0.2, horizontal_flip=True, fill_mode='nearest')\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow(train_images, train_labels, batch_size=20, shuffle=True)\n",
    "test_generator = test_datagen.flow(test_images, test_labels, batch_size=20, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df2f2f1c-0faf-436c-987d-faae406106ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-16 13:13:37.727528: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 5s 177ms/step - loss: 0.5740 - accuracy: 0.7118\n",
      "Epoch 2/10\n",
      "24/24 [==============================] - 4s 161ms/step - loss: 0.3203 - accuracy: 0.8387\n",
      "Epoch 3/10\n",
      "24/24 [==============================] - 4s 164ms/step - loss: 0.4078 - accuracy: 0.7204\n",
      "Epoch 4/10\n",
      "24/24 [==============================] - 4s 162ms/step - loss: 0.2056 - accuracy: 0.9097\n",
      "Epoch 5/10\n",
      "24/24 [==============================] - 4s 156ms/step - loss: 0.2045 - accuracy: 0.9097\n",
      "Epoch 6/10\n",
      "24/24 [==============================] - 4s 157ms/step - loss: 0.1546 - accuracy: 0.9441\n",
      "Epoch 7/10\n",
      "24/24 [==============================] - 4s 160ms/step - loss: 0.1380 - accuracy: 0.9398\n",
      "Epoch 8/10\n",
      "24/24 [==============================] - 4s 161ms/step - loss: 0.0839 - accuracy: 0.9548\n",
      "Epoch 9/10\n",
      "24/24 [==============================] - 4s 157ms/step - loss: 0.2132 - accuracy: 0.9140\n",
      "Epoch 10/10\n",
      "24/24 [==============================] - 4s 168ms/step - loss: 0.2047 - accuracy: 0.9247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-16 13:14:18.267647: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 17ms/step - loss: 0.2860 - accuracy: 0.8500\n",
      "Test loss, test acc: [0.28596049547195435, 0.8500000238418579]\n"
     ]
    }
   ],
   "source": [
    "# Model setup\n",
    "model = create_binary_classification_cnn((128, 128, 3))\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Fit model\n",
    "if steps_per_epoch > 0:\n",
    "    model.fit(train_generator, steps_per_epoch=steps_per_epoch, epochs=10)\n",
    "\n",
    "# Evaluate model\n",
    "if validation_steps > 0:\n",
    "    results = model.evaluate(test_generator, steps=validation_steps)\n",
    "    print(\"Test loss, test acc:\", results)\n",
    "else:\n",
    "    print(\"Validation steps issue: check the division for batch size and total samples.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "435ebc0a-fd91-4e1c-8bb2-0fe1dcdff3de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-16 13:14:18.563602: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9.6756595e-01]\n",
      " [9.7401100e-01]\n",
      " [8.6042982e-01]\n",
      " [9.4873935e-01]\n",
      " [8.6156619e-01]\n",
      " [6.3106710e-01]\n",
      " [7.5897712e-01]\n",
      " [8.8132846e-01]\n",
      " [6.1045891e-01]\n",
      " [8.2249540e-01]\n",
      " [7.9059720e-01]\n",
      " [7.1347845e-01]\n",
      " [7.7578276e-01]\n",
      " [8.8971031e-01]\n",
      " [9.0936321e-01]\n",
      " [8.1185114e-01]\n",
      " [7.1082056e-01]\n",
      " [9.8231411e-01]\n",
      " [9.8290390e-01]\n",
      " [9.6987508e-02]\n",
      " [7.4109620e-01]\n",
      " [3.9534122e-01]\n",
      " [6.3964516e-01]\n",
      " [7.3865622e-01]\n",
      " [8.6163753e-01]\n",
      " [9.6369362e-01]\n",
      " [8.5740674e-01]\n",
      " [9.6330231e-01]\n",
      " [6.3528764e-01]\n",
      " [8.5449725e-01]\n",
      " [9.7560602e-01]\n",
      " [2.8992406e-01]\n",
      " [5.2230424e-01]\n",
      " [7.2852367e-01]\n",
      " [9.0885156e-01]\n",
      " [8.7251848e-01]\n",
      " [4.0637156e-01]\n",
      " [5.1369476e-01]\n",
      " [9.2329091e-01]\n",
      " [8.1138444e-01]\n",
      " [7.8278559e-01]\n",
      " [3.5546422e-05]\n",
      " [4.4756535e-02]\n",
      " [1.2536579e-03]\n",
      " [6.2441942e-03]\n",
      " [7.3904760e-02]\n",
      " [6.4186436e-01]\n",
      " [1.5138403e-01]\n",
      " [2.2808143e-03]\n",
      " [5.4273206e-01]\n",
      " [5.3505880e-01]\n",
      " [5.5792279e-13]\n",
      " [8.1712049e-15]\n",
      " [2.7987664e-11]\n",
      " [2.8328485e-11]\n",
      " [1.5976817e-11]\n",
      " [6.4011204e-13]\n",
      " [4.0910684e-02]\n",
      " [7.1285486e-01]\n",
      " [2.5023887e-02]\n",
      " [2.0195164e-01]\n",
      " [2.0590867e-01]\n",
      " [7.1889347e-01]\n",
      " [6.5990919e-01]\n",
      " [4.8219272e-01]\n",
      " [3.7142234e-03]\n",
      " [3.6162790e-02]\n",
      " [5.9232591e-03]\n",
      " [5.2046537e-01]\n",
      " [6.3018900e-01]\n",
      " [2.5014958e-12]\n",
      " [1.8766998e-11]\n",
      " [2.8382732e-11]\n",
      " [3.7845424e-15]\n",
      " [1.4662391e-10]\n",
      " [4.8294090e-04]\n",
      " [4.2694187e-10]\n",
      " [5.8577973e-03]\n",
      " [3.9007730e-09]\n",
      " [2.8463682e-14]]\n"
     ]
    }
   ],
   "source": [
    "# Predict on the test data\n",
    "predictions = model.predict(test_generator, steps=validation_steps)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4198c05e-c51e-4dbd-ad29-42028fd7663f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 26ms/step\n",
      "[0.9992271] The image is classified as a Church.\n"
     ]
    }
   ],
   "source": [
    "# Single image prediction example\n",
    "img_path = 'bothalf.png'\n",
    "img = image.load_img(img_path, target_size=(128, 128))\n",
    "img_array = image.img_to_array(img)\n",
    "img_array = np.expand_dims(img_array, axis=0)\n",
    "img_array /= 255.0\n",
    "prediction = model.predict(img_array)\n",
    "if prediction[0] > 0.5:\n",
    "    print(str(prediction[0]) + \" The image is classified as a Church.\")\n",
    "else:\n",
    "    print(str(prediction[0]) + \" The image is not classified as a Church.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d8f8f163-e844-400b-b165-f7774d545426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 922ms/step - loss: 1.6962 - accuracy: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "# Telling machine that it is wrong (retraining on single image prediction)\n",
    "def retrain_model_on_feedback(model, img_path, actual_label, learning_rate=0.01):\n",
    "    # Load image\n",
    "    img = image.load_img(img_path, target_size=(128, 128))\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    img_array /= 255.0\n",
    "\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    actual_label = np.array([actual_label])\n",
    "\n",
    "    # Train the model on this one instance where machine was wrong\n",
    "    model.fit(img_array, actual_label, epochs=1)\n",
    "\n",
    "# Example of using the function\n",
    "img_path = 'upsidedown.png'\n",
    "actual_label = 1  # Correct label if the prediction was wrong\n",
    "retrain_model_on_feedback(model, img_path, actual_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04243303-7364-44e3-98dc-868cb0dcf6eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
